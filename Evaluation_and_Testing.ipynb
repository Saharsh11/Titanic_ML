{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation_and Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_kEEXFBoTA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from time import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHj1tDycEZjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_feature = pd.read_csv('././Titanic_x_val.csv')\n",
        "val_label = pd.read_csv('././Titanic_y_val.csv')\n",
        "\n",
        "test_feature = pd.read_csv('././Titanic_x_test.csv')\n",
        "test_label = pd.read_csv('././Titanic_y_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMgHZcg3M3ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {}\n",
        "for mdl in ['LR','SVM','MLP','RF','GB']:\n",
        "  models[mdl]=  joblib.load('././{}_model.pkl'.format(mdl))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMg0v2_lOsXB",
        "colab_type": "text"
      },
      "source": [
        "Defining function for evaluating all models based on their Accuracy(total predicted/ total survived), Precision(true positive for survived/total predicted survived), Recall(true positive survived/total actual survived)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teum9bKBOcuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(name, model , feature, label):\n",
        "  start = time()\n",
        "  pred = model.predict(feature)\n",
        "  end = time()\n",
        "  accuracy = round(accuracy_score(label,pred),4)\n",
        "  presision = round(precision_score(label,pred),4)\n",
        "  recall = round(recall_score(label,pred),4)\n",
        "  print('{} == Accuracy: {}, Precision: {}, recall: {},Time: {}'.format(name,\n",
        "                                                                     accuracy,\n",
        "                                                                     presision,\n",
        "                                                                     recall,\n",
        "                                                                     round((end-start),3)))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY6MwvYiTTkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "52ca2406-4b1b-4730-e6d0-367715c113e7"
      },
      "source": [
        "print('For Validation:')\n",
        "for name, mdl in models.items():\n",
        "  eval_model(name, mdl,val_feature,val_label)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Validation:\n",
            "LR == Accuracy: 0.8146, Precision: 0.8167, recall: 0.6901,Time: 0.002\n",
            "SVM == Accuracy: 0.809, Precision: 0.8136, recall: 0.6761,Time: 0.002\n",
            "MLP == Accuracy: 0.7865, Precision: 0.8367, recall: 0.5775,Time: 0.003\n",
            "RF == Accuracy: 0.8258, Precision: 0.8333, recall: 0.7042,Time: 0.012\n",
            "GB == Accuracy: 0.8258, Precision: 0.8333, recall: 0.7042,Time: 0.003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_IRU7gPVVu0",
        "colab_type": "text"
      },
      "source": [
        "Since the Validaiton is nearly samefor both RandomForest and GradantBoosting hence We will test the model for both and the try to understand how both models predicted are better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_vpkRi5Vwrl",
        "colab_type": "text"
      },
      "source": [
        "Now Testing the dataset for models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjbYt_rsVpDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f6706c90-279f-4992-8a14-01c1567c265b"
      },
      "source": [
        "eval_model('Random Forest', models['RF'],test_feature, test_label)\n",
        "eval_model('Gradient Boosting', models['RF'],test_feature, test_label)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest == Accuracy: 0.7821, Precision: 0.7377, recall: 0.6618,Time: 0.034\n",
            "Gradient Boosting == Accuracy: 0.7821, Precision: 0.7377, recall: 0.6618,Time: 0.013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NejeMeuaYSGT",
        "colab_type": "text"
      },
      "source": [
        "Doing Testing from all models to compare and understand how the values are affected by different values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3PCLZw6Xr6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "d7a4bbe0-7e25-43ce-a259-bc8a98f82459"
      },
      "source": [
        "print('For Testing all models:')\n",
        "for name, mdl in models.items():\n",
        "  eval_model(name, mdl,test_feature,test_label)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Testing all models:\n",
            "LR == Accuracy: 0.7933, Precision: 0.7719, recall: 0.6471,Time: 0.011\n",
            "SVM == Accuracy: 0.7654, Precision: 0.7167, recall: 0.6324,Time: 0.004\n",
            "MLP == Accuracy: 0.8045, Precision: 0.8511, recall: 0.5882,Time: 0.003\n",
            "RF == Accuracy: 0.7821, Precision: 0.7377, recall: 0.6618,Time: 0.016\n",
            "GB == Accuracy: 0.8045, Precision: 0.8, recall: 0.6471,Time: 0.004\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}